# AI and ML Fundamentals
## 1. What is AI
- Artificial Intelligence (AI): Machines that perform tasks that **mimic human behavior**.
- Machine Learning (ML): Machines that improve at a task **without explicit programming**.
- Deep Learning (DL): A subset of ML that uses **artificial neural networks**, inspired by the **human brain**, to solve complex problems.
- Generative AI (GenAI): A specialized subset of AI that **generates content** such as:
Image, Video, Text, Audio.

## 2. AI vs Generative AI
### What is Artificial Intelligence (AI)?
AI refers to computer systems that perform tasks typically requiring human intelligence, such as:
- Problem-solving
- Decision-making
- Understanding natural language
- Recognizing speech and images

### AI‚Äôs goal:
To interpret, analyze, and respond to human actions, simulating human intelligence in machines.

- Key Concepts:
  - Simulate: Mimics aspects and behavior.
  - Emulate: Replicates exact processes and mechanisms.

### AI Applications:
- Expert systems
- Natural language processing (NLP)
- Speech recognition
- Robotics

### Industry Use Cases:
- Customer service: B2C chatbots
- E-commerce: Recommendation systems
- Automotive: Autonomous vehicles
- Medical: Diagnosis and treatment support

### What is Generative AI (GenAI)?
A subset of AI focused on creating new content or data that is novel and realistic.
Unlike traditional AI, GenAI can generate new data itself.


Examples:
Generating text, images, music, speech, and other forms of media.

### Key Technologies:
- Generative Adversarial Networks (GANs)
- Variational Autoencoders (VAEs)
- Transformer models (e.g., GPT)

GenAI Modalities(sensens like human touch, listen & so on):
- Vision: Creating realistic images/videos
- Text: Generating human-like text
- Audio: Composing music
- Molecular: Drug discovery using genomic data

### Important Term:

Large Language Models (LLMs) ‚Üí A subset of GenAI that specializes in generating human-like text.
Often confused with general AI due to its popularity

### Comparison: AI vs Generative AI

| Category | Artificial Intelligence (AI) | Generative AI (GenAI)|
|-----:|---------------|---------------|
|     Functionality|Focuses on understanding and decision-making |Focuses on creating new, original content|
|     Data Handling|Uses existing data for analysis and decision-making	|Uses existing data to generate new unseen outputs|
|     Applications| Used across multiple industries for automation, NLP, data analysis, and healthcare|Focuses on creative content generation, deepfakes, and synthetic data|


## 3. What is Jupyter Notebook?
Jupyter Notebook is a web-based application for creating documents that combine:
- Live code
- Narrative text
- Equations
- Visualizations

Originally developed as part of IPython, Jupyter Notebooks evolved into a standalone tool.

### What is JupyterLab?
JupyterLab is the next-generation web-based user interface for Jupyter.
It includes:
- Notebook
- Terminal
- Text Editor
- File Browser
- Rich Outputs

‚úÖ Combines flexibility and power in one interface.
üîÑ JupyterLab will eventually replace Jupyter Notebook.

### What is JupyterHub?
JupyterHub is a server-based platform that runs JupyterLab for multiple users.
Ideal for:
- üë©‚Äçüè´ A class of students
- üè¢ Corporate data science teams
- üî¨ Scientific research groups

It manages authentication, spawns individual notebook instances, and controls access.

## 4.Natural Language Processing (NLP)
- Definition:
Natural Language Processing (NLP) is a Machine Learning technique that enables computers to understand the context of a corpus (a body of related text).
- Key Functions of NLP
  - Analyze and interpret text (e.g., emails, documents).
  - Interpret spoken language (e.g., sentiment analysis).
  - Synthesize speech (e.g., voice assistants).
  - Translate spoken or written phrases between languages.
  - Interpret commands and determine appropriate actions.
### Core Components of NLP
- Text Wrangling and Pre-Processing
  - Conversion ‚Äì Transform text into a standardized format.
  - Sanitization ‚Äì Remove noise, unnecessary characters.
  - Tokenization ‚Äì Split text into words or phrases.
  - Stemming ‚Äì Reduce words to their root form (e.g., "running" ‚Üí "run").
  - Lemmatization ‚Äì Normalize words based on their dictionary meaning.
- Language Understanding (Structure/Syntax)
  - Parts of Speech (POS) Tagging ‚Äì Identify nouns, verbs, adjectives, etc.
  - Chunking ‚Äì Group related words together.
  - Dependency Parsing ‚Äì Analyze grammatical relationships in a sentence.
  - Constituency Parsing ‚Äì Break down a sentence into hierarchical sub-units.
- Processing and Functionality
  - Named Entity Recognition (NER) ‚Äì Identify proper names (e.g., people, places).
  - N-gram Identification ‚Äì Analyze word sequences to predict text.
  - Sentiment Analysis ‚Äì Detect emotions and opinions in text.
  - Information Extraction ‚Äì Identify key information from unstructured data.
  - Information Retrieval ‚Äì Find relevant documents or data.
  - Questions and Answering ‚Äì Process user queries for precise answers.
  - Topic Modeling ‚Äì Identify key themes in text data.

## 5. Regression Study Notes
- What is Regression?
Regression is the process of finding a function to correlate a labeled dataset into a continuous variable/number.
Outcome: Predict a variable in the future, e.g., "What will the temperature be next week?" (20¬∞C).
- Key Concepts
  - Vectors (dots): Represent data points plotted on a graph (e.g., X, Y dimensions).
  - Regression Line: A line drawn through the dataset to minimize the error between predicted and actual values.
  - Error: The distance of the vector (data point) from the regression line.
- Types of Errors Used in Regression
  - Mean Squared Error (MSE):
    - Calculates the average of the squared differences between predicted and actual values.
    - Purpose: Penalizes larger errors more heavily.
    - Use Case: Suitable when large errors are highly critical.
  - Root Mean Squared Error (RMSE)
    - Square root of MSE, returning error to the same units as the target variable (e.g., ¬∞C).
    - Purpose: Easier to interpret due to matching units.
    - Use Case: Commonly used for evaluating model performance.
  - Mean Absolute Error (MAE)
    - Calculates the average of the absolute differences between predicted and actual values.
    - Purpose: Treats all errors equally without amplifying larger deviations.
    - Use Case: Robust to outliers and provides a simple measure of deviation.
- Key Points to Remember
  - Lower Error Values = Better Model Performance.
  - Use MSE or RMSE when larger errors are more problematic.
  - Use MAE for a simpler, more balanced error measurement.
- Example Use Case
  - Predicting the temperature next week based on past weather data using regression analysis.

## 6.Classification
- Definition
Classification is a process of finding a function to divide a **labeled** dataset into classes/categories.
- Example
Predicting a category based on input data.
- Example Question: Will it rain next Saturday?
Possible categories: Sunny, Rainy.
- Key Concept
  - A classification line separates the dataset into different classes.
  - Data on one side belongs to Sunny.
  - Data on the other side belongs to Rainy.
- Classification Algorithms
  - Logistic Regression
  - Decision Tree / Random Forest
  - Neural Networks
  - Na√Øve Bayes
  - K-Nearest Neighbors (KNN)
  - Support Vector Machines (SVM)

## 7. Clustering
Is a algorithum to classify **unlabbled** data 

## 8. Types of Machine Learning
### Learning Problems
- 1. Supervised Learning
  - Definition: The model learns from labeled data to predict outcomes for new, unseen data.
  - Example: Predicting house prices using historical data with features like square footage, number of bedrooms, and location.
  - Input: Data with labels (e.g., features of a house and its price).
  - Output: Predicted price.
  - Key Point: Requires a fully labeled dataset.
- 2. Unsupervised Learning
  - Definition: The model discovers patterns or groupings in data without labels.
  - Example: Customer segmentation in marketing.
  - Input: Customer purchasing behavior without predefined labels.
  - Output: Clusters like "frequent buyers" and "one-time shoppers."
  - Key Point: Focuses on pattern recognition, not predictions.
- 3. Reinforcement Learning
  - Definition: An agent learns by interacting with the environment and receiving feedback in the form of rewards or penalties.
  - Example: A robot learning to walk by adjusting its steps and being rewarded for stability.
  - Input: Current state (e.g., balance).
  - Output: Action (e.g., adjust leg movement).
  - Key Point: Focuses on trial and error.
### Hybrid Learning Problems
- 1. Semi-Supervised Learning
  - Definition: Combines a small amount of labeled data with a large amount of unlabeled data to improve learning.
  - Example: Identifying fraudulent transactions in banking when only a few transactions are labeled as fraudulent.
  - Labeled data: A small subset of transactions.
  - Unlabeled data: Thousands of other transactions.
- 2. Self-Supervised Learning
  - Definition: Automatically generates pseudo-labels from unlabeled data to train a model.
  - Example: Training a language model like GPT using massive amounts of text by predicting the next word in a sentence.
  - Input: "Machine learning is‚Ä¶"
  - Output: The model predicts "fun."
- 3. Multi-Instance Learning
  - Definition: Instead of labeling individual examples, groups (bags) of examples are labeled.
  - Example: Determining whether a medical scan (bag) contains cancerous cells (positive label), even though individual images (instances) are not labeled.
### Statistical Inference
- 1. Inductive Inference
  - Definition: Derives conclusions by observing patterns in the data.
  - Example: After observing that "all apples on the tree are red," infers that "all apples on the tree must be red."
- 2. Deductive Inference
  - Definition: Applies general rules to draw specific conclusions.
  - Example:
Rule: "All cats are mammals."
Observation: "Luna is a cat."
Conclusion: "Luna is a mammal."
- 3. Transductive Inference
  - Definition: Focuses on making specific predictions for known data without generalizing.
  - Example: Predicting student performance on specific test questions without building a general model for all tests.
### Learning Techniques
- 1. Multi-Task Learning
  - Definition: Solves multiple related problems simultaneously.
  - Example: A model trained to recognize both facial expressions (emotion detection) and gender from the same images.
- 2. Active Learning
  - Definition: The model queries a human for labels when it is unsure.
  - Example: A document classification system asks a human to label ambiguous emails (e.g., "spam or not spam?").
- 3. Online Learning
  - Definition: Continuously updates the model with new data.
  - Example: Stock market prediction models that are updated as new trading data arrives.
- 4. Transfer Learning
  - Definition: A pre-trained model is adapted for a new, related task.
  - Example:
    - Task 1: Training a model on a large dataset of general images.
    - Task 2: Using the trained model to recognize medical images like X-rays.
- 5. Ensemble Learning
  - Definition: Combines multiple models to improve performance.
  - Example:
    - Random Forest: Combines multiple decision trees.
    - Voting Ensemble: Uses the majority vote from multiple classifiers for prediction.
### Key Takeaways
- Supervised Learning: Requires labeled data.
- Unsupervised Learning: Focuses on finding patterns in unlabeled data.
- Reinforcement Learning: Uses feedback (reward/punishment) to learn actions.
- Hybrid Problems: Combine supervised and unsupervised methods for specialized tasks.
- Techniques: Focus on optimization (e.g., transfer learning for efficiency, ensemble for accuracy).

