# 1. AI vs GEN AI
- AI's goal is to interpret, analyse adn response to human action. To simulate humal intelligence in machine
- Gen AI is focuses on creating new content or data

# 2. What is foundational model
A FM is a general purpose model that is trained on vast amounts of data. 

# 3. What is LLM 
- A LLLM is a foundational model that implements the transformaer architecture.
- During training phase, the model learns sematics (patterns) of language, such as grammer, word usage, sentence structure, style and tone.

# 3 Transformaer architecture 
Transformaer architecture was developed by research at Google that is effective at NLP due to **multi-head attention** and **positional encoding**.

- transformer atchiture consist two parts
  - Encoder: Reads and understands the input text
  - Decoder: Based on encoder learning m this part **generates new piece of text**

# 4 Tokenization
It hte process of breaking data input (text) into smaller parts
Tokenization Algorithms:
- Byte Pair Encoding (BPE) used by GPT 3
- WordPiece used by BERT
- SetencePiece used by Google T5 or GPT 3.5
When working with a LLMs, the input text must be converted ( tokenized) into  sequence of token **that match the model's internal vocabulary.**

# 5 Tiken and apacity 
When using transformer the decoder continuosly feeds the sequence of tokens back in as output to help predict the next word in the input.
Capacity requires:
- MemoryL
  - each token in a sequence requiers memory
  - as the token count increases, the memory increses
  - The memory usage eventually becomes exhausted.
- Compute
  - Model perform more operations for each additional token
  - Longer sequences requier more compute

# 6 Embeddings





